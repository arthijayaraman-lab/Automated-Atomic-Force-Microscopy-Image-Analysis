{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s9gj8w-AonXo",
    "outputId": "1e8181c1-9267-4c6c-ab73-071276f1427f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting porespy\n",
      "  Using cached porespy-2.4.1-py3-none-any.whl (164 kB)\n",
      "Requirement already satisfied: dask in /usr/local/lib/python3.10/dist-packages (from porespy) (2023.8.1)\n",
      "Collecting deprecated (from porespy)\n",
      "  Using cached Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting edt (from porespy)\n",
      "  Using cached edt-2.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from porespy) (3.7.1)\n",
      "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from porespy) (0.58.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from porespy) (1.25.2)\n",
      "Collecting openpnm (from porespy)\n",
      "  Using cached openpnm-3.4.1-py3-none-any.whl (304 kB)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from porespy) (2.0.3)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from porespy) (5.9.5)\n",
      "Requirement already satisfied: pywavelets in /usr/local/lib/python3.10/dist-packages (from porespy) (1.6.0)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from porespy) (13.7.1)\n",
      "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from porespy) (0.19.3)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from porespy) (1.11.4)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from porespy) (67.7.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from porespy) (4.66.2)\n",
      "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from dask->porespy) (8.1.7)\n",
      "Requirement already satisfied: cloudpickle>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from dask->porespy) (2.2.1)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.10/dist-packages (from dask->porespy) (2023.6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from dask->porespy) (24.0)\n",
      "Requirement already satisfied: partd>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from dask->porespy) (1.4.1)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from dask->porespy) (6.0.1)\n",
      "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from dask->porespy) (0.12.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.13.0 in /usr/local/lib/python3.10/dist-packages (from dask->porespy) (7.1.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated->porespy) (1.14.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->porespy) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->porespy) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->porespy) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->porespy) (1.4.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->porespy) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->porespy) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->porespy) (2.8.2)\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->porespy) (0.41.1)\n",
      "Collecting chemicals (from openpnm->porespy)\n",
      "  Using cached chemicals-1.1.5-py3-none-any.whl (23.9 MB)\n",
      "Collecting docrep (from openpnm->porespy)\n",
      "  Using cached docrep-0.3.2-py3-none-any.whl\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from openpnm->porespy) (3.9.0)\n",
      "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from openpnm->porespy) (4.19.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from openpnm->porespy) (3.3)\n",
      "Collecting pyamg (from openpnm->porespy)\n",
      "  Using cached pyamg-5.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.9 MB)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from openpnm->porespy) (1.12)\n",
      "Collecting thermo (from openpnm->porespy)\n",
      "  Using cached thermo-0.2.27-py3-none-any.whl (10.4 MB)\n",
      "Collecting transforms3d (from openpnm->porespy)\n",
      "  Using cached transforms3d-0.4.1-py3-none-any.whl (1.4 MB)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->porespy) (2023.4)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->porespy) (2024.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->porespy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->porespy) (2.16.1)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->porespy) (2.31.6)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->porespy) (2024.4.24)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.13.0->dask->porespy) (3.18.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->porespy) (0.1.2)\n",
      "Requirement already satisfied: locket in /usr/local/lib/python3.10/dist-packages (from partd>=1.2.0->dask->porespy) (1.0.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->porespy) (1.16.0)\n",
      "Collecting fluids>=1.0.23 (from chemicals->openpnm->porespy)\n",
      "  Using cached fluids-1.0.25-py3-none-any.whl (1.5 MB)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->openpnm->porespy) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->openpnm->porespy) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->openpnm->porespy) (0.35.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->openpnm->porespy) (0.18.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->openpnm->porespy) (1.3.0)\n",
      "Installing collected packages: transforms3d, edt, docrep, deprecated, pyamg, fluids, chemicals, thermo, openpnm, porespy\n",
      "Successfully installed chemicals-1.1.5 deprecated-1.2.14 docrep-0.3.2 edt-2.4.0 fluids-1.0.25 openpnm-3.4.1 porespy-2.4.1 pyamg-5.1.0 thermo-0.2.27 transforms3d-0.4.1\n",
      "Requirement already satisfied: pypardiso in /usr/local/lib/python3.10/dist-packages (0.4.6)\n",
      "Requirement already satisfied: mkl!=2024.0 in /usr/local/lib/python3.10/dist-packages (from pypardiso) (2023.2.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pypardiso) (1.25.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pypardiso) (1.11.4)\n",
      "Requirement already satisfied: intel-openmp==2023.* in /usr/local/lib/python3.10/dist-packages (from mkl!=2024.0->pypardiso) (2023.2.4)\n",
      "Requirement already satisfied: tbb==2021.* in /usr/local/lib/python3.10/dist-packages (from mkl!=2024.0->pypardiso) (2021.12.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install porespy\n",
    "!pip3 install pypardiso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "YnTyLRaEnK3g"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-02 11:02:51.362681: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-02 11:02:51.384043: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-02 11:02:51.384061: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-02 11:02:51.384683: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-02 11:02:51.388666: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-02 11:02:51.826039: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/p51pro/anaconda3/envs/porespy/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Model\n",
    "import pywt\n",
    "import porespy as ps\n",
    "import scipy.ndimage as spim\n",
    "from skimage.transform import radon\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.fftpack import dct\n",
    "import time\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from matplotlib.ticker import FormatStrFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a1Na0ugXrNnw",
    "outputId": "69420705-9a97-4ab4-99dc-7e692a9ef8e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dft', 'dlresnet50']\n",
      "dft\n",
      "-------------------\n",
      "(784, 3)\n",
      "dlresnet50\n",
      "(98, 32, 32, 3)\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "(98, 32, 32, 3)\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "(98, 32, 32, 3)\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "(98, 32, 32, 3)\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "(98, 32, 32, 3)\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "(98, 32, 32, 3)\n",
      "4/4 [==============================] - 0s 995us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "(98, 32, 32, 3)\n",
      "4/4 [==============================] - 0s 976us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "(98, 32, 32, 3)\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "-------------------\n",
      "(784, 384)\n",
      "(784, 387)\n"
     ]
    }
   ],
   "source": [
    "class Segment:\n",
    "  def __init__(self, pca_comp = 3, pca_apply=False, win_ratio = 0.03, transform_string = \"dft\", stand_out_features = True, eql_hist = False, use_kmeans = True, use_gmm = False, no_clusters = 2, stats_to_use = \"va\", um_pix=5.21):\n",
    "    self.pca_comp = pca_comp\n",
    "    self.pca_apply = pca_apply\n",
    "    self.win_ratio = win_ratio\n",
    "    self.transform_string = transform_string\n",
    "    self.stand_out_features = stand_out_features\n",
    "    self.eql_hist = eql_hist\n",
    "    self.use_kmeans = use_kmeans\n",
    "    self.use_gmm = use_gmm\n",
    "    self.no_clusters = no_clusters\n",
    "    self.stats_to_use = stats_to_use\n",
    "    self.um_pix=um_pix\n",
    "    self.model_stack = []\n",
    "    self.layer_names = ['conv1_relu', 'conv2_block3_2_relu', 'conv3_block1_2_relu']\n",
    "\n",
    "    self.input_path = \"/home/p51pro/UD/jayraman_lab/Auto_afm/analysis/images_for_si/input_test\"\n",
    "    self.output_path = \"/home/p51pro/UD/jayraman_lab/Auto_afm/analysis/images_for_si/radon_regen\"\n",
    "\n",
    "    self.transform_list = self.get_transform_list()\n",
    "\n",
    "  def get_transform_list(self):\n",
    "    transform_list = self.transform_string.split(\"_\")\n",
    "    return transform_list\n",
    "  ############################################\n",
    "  ############# Loop functions ###############\n",
    "  ############################################\n",
    "\n",
    "  def get_features(self, img1, transform):\n",
    "    \"\"\"\n",
    "    function to make features on tile\n",
    "    features:\n",
    "      1. transforms functions\n",
    "      2. which transform to use\n",
    "    return:\n",
    "      1. feature vector\n",
    "    \"\"\"\n",
    "    if \"dlresnet50\" in transform:\n",
    "      self.load_ResNet50()\n",
    "      all_features = self.get_ResNet50(img1)\n",
    "    else:\n",
    "      all_features = np.array([])\n",
    "    if \"radon\" in transform :\n",
    "      all_features=np.append(all_features,self.get_radon_features(img1), axis=0)\n",
    "    if \"dft\" in transform :\n",
    "      all_features=np.append(all_features,self.get_dft_features(img1), axis=0)\n",
    "    if \"dct\" in transform :\n",
    "      all_features=np.append(all_features,self.get_dct_features(img1), axis=0)\n",
    "    if \"dwt_biort\" in transform :\n",
    "      all_features=np.append(all_features,self.get_biort_features(img1), axis=0)\n",
    "    if \"dwt_haar\" in transform :\n",
    "      all_features=np.append(all_features,self.get_wavelget_haar_featureset_features(img1), axis=0)\n",
    "    return all_features\n",
    "\n",
    "  def slinding_window(self, img):\n",
    "    \"\"\"\n",
    "    function to make tiles\n",
    "    features:\n",
    "      1. win_factor\n",
    "      2. input image\n",
    "      3. using resnet or deomain transform for tile size\n",
    "    return:\n",
    "      1. feature cube flattened\n",
    "      2. output width\n",
    "      3. output height\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    print(self.transform_list)\n",
    "    for transform in self.transform_list:\n",
    "      print(transform)\n",
    "      img_features = []\n",
    "      if \"dlresnet50\" in self.transform_list:\n",
    "        win_siz = 32\n",
    "        img_tiles = []\n",
    "      else:\n",
    "        win_siz = round((img.shape[0]*self.win_ratio + img.shape[1]*self.win_ratio)/2)\n",
    "\n",
    "      i_ctr = 0\n",
    "      for i in range(win_siz//2,img.shape[0]-(win_siz//2),1):\n",
    "        j_ctr = 0\n",
    "        for j in range(win_siz//2,img.shape[1]-(win_siz//2),1):\n",
    "          if \"dlresnet50\" in transform:\n",
    "            img_tiles.append(img[(i-(win_siz//2)):(i+(win_siz//2)), (j-(win_siz//2)):(j+(win_siz//2))])\n",
    "          else:\n",
    "            img_features.append(self.get_features(img[(i-(win_siz//2)):(i+(win_siz//2)), (j-(win_siz//2)):(j+(win_siz//2))],transform))\n",
    "          j_ctr+=1\n",
    "        i_ctr+=1\n",
    "      if \"dlresnet50\" in transform:\n",
    "        img_features = self.get_features(img_tiles, transform)\n",
    "      img_features = np.array(img_features)\n",
    "      print(\"-------------------\")\n",
    "      print(img_features.shape)\n",
    "      if \"all_trans_features\" not in locals():\n",
    "        all_trans_features = img_features.copy()\n",
    "      else:\n",
    "        all_trans_features = np.append(all_trans_features, img_features, axis=1)\n",
    "\n",
    "    return all_trans_features, i_ctr, j_ctr\n",
    "\n",
    "  ############################################\n",
    "  ############## DL ResNet50 #################\n",
    "  ############################################\n",
    "\n",
    "  def load_ResNet50(self):\n",
    "    \"\"\"\n",
    "    Features:\n",
    "      1. weights\n",
    "      2. input_shape\n",
    "      3. number of layers\n",
    "      4. which layers\n",
    "      5. model type\n",
    "      6. Model type\n",
    "    Return:\n",
    "      1. tf_model, tf_model, ...\n",
    "\n",
    "    \"\"\"\n",
    "    model = tf.keras.applications.resnet50.ResNet50(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_tensor=None,\n",
    "        input_shape=(32,32,3),\n",
    "        pooling=None\n",
    "    )\n",
    "\n",
    "    for lyr in self.layer_names:\n",
    "      self.model_stack.append(Model(inputs=model.input, outputs=model.get_layer(lyr).output))\n",
    "    return self.model_stack\n",
    "\n",
    "  def get_ResNet50(self, img):\n",
    "    \"\"\"\n",
    "    Features:\n",
    "      1. statistics\n",
    "      2. no of layers\n",
    "      3. prime factor shit\n",
    "      4. img\n",
    "      5. model from load resnet\n",
    "\n",
    "    return:\n",
    "      1. Features\n",
    "\n",
    "    \"\"\"\n",
    "    img = np.array(img)\n",
    "    img = np.repeat(img[:, :, :, np.newaxis], 3, axis=3) # repeat gray scale image into 3 channels like rgb\n",
    "\n",
    "    for img_t in np.split(img, 8, axis=0):  #maxPrimeFactors(img.shape[0])\n",
    "      if len(self.model_stack)>0:\n",
    "        print(img_t.shape)\n",
    "        output_1 = self.model_stack[0].predict(img_t)\n",
    "        features = np.max(output_1,axis=(1, 2))\n",
    "        features = np.append(features, np.mean(output_1,axis=(1, 2)), axis =1)\n",
    "        features = np.append(features, np.var(output_1,axis=(1, 2)), axis =1)\n",
    "      if len(self.model_stack)>1:\n",
    "        output_2 = self.model_stack[1].predict(img_t)\n",
    "        features = np.append(features, np.max(output_2,axis=(1, 2)), axis =1)\n",
    "        features = np.append(features, np.mean(output_2,axis=(1, 2)), axis =1)\n",
    "        features = np.append(features, np.var(output_2,axis=(1, 2)), axis =1)\n",
    "      if len(self.model_stack)>2:\n",
    "        output_3 = self.model_stack[2].predict(img_t)\n",
    "        features = np.append(features, np.max(output_3,axis=(1, 2)), axis =1)\n",
    "        features = np.append(features, np.mean(output_3,axis=(1, 2)), axis =1)\n",
    "        features = np.append(features, np.var(output_3,axis=(1, 2)), axis =1)\n",
    "      if 'out_features' not in locals():\n",
    "        out_features = features.copy()\n",
    "      else:\n",
    "        out_features = np.append(out_features,features, axis = 0)\n",
    "    \n",
    "    return out_features\n",
    "\n",
    "\n",
    "\n",
    "  ############################################\n",
    "  ########### Domain Transforms ##############\n",
    "  ############################################\n",
    "\n",
    "  ####### Discrete Cosine transforms ########\n",
    "  def get_dct_features(self, tile):\n",
    "    \"\"\"\n",
    "    Discrete cosine transform (DCT) based feature extraction\n",
    "    features:\n",
    "      1. DCT norm\n",
    "      2. stats used\n",
    "      3. input tile image\n",
    "    return\n",
    "      1. feautre vector\n",
    "    \"\"\"\n",
    "    dct_image = dct(dct(tile.T, norm='ortho').T, norm='ortho')\n",
    "    return self.get_stats_feature_vector(dct_image)\n",
    "\n",
    "  ###### Discrete Fourirer transforms ########\n",
    "\n",
    "  def get_dft_features(self, tile):\n",
    "    \"\"\"\n",
    "    Discrete fourier transform (DFT) based feature extraction\n",
    "    features:\n",
    "      1. stats used\n",
    "      2. input tile image\n",
    "    return\n",
    "      1. feautre vector\n",
    "    \"\"\"\n",
    "    dft_image = np.fft.fft2(tile)\n",
    "    dft_image = np.fft.fftshift(dft_image)\n",
    "    return self.get_stats_feature_vector(dft_image)\n",
    "\n",
    "\n",
    "  ########## Wavelet transforms ##############\n",
    "  def get_biort_features(self, tile, level=2):\n",
    "    \"\"\"\n",
    "    Discrete wavelet transform (DWT) bi-orthogonal wavelet based feature extraction\n",
    "\n",
    "    features:\n",
    "      1. stats used\n",
    "      2. input tile image\n",
    "      3. wavelet type\n",
    "      4. level of decomposition\n",
    "      5. coeff to use\n",
    "    return\n",
    "      1. feautre vector\n",
    "    \"\"\"\n",
    "\n",
    "    coeffs = pywt.swt2(tile, 'bior5.5', start_level=0, level = level)\n",
    "    cD = coeffs[:][1]\n",
    "    texture_features = []\n",
    "    for detail_coeff_ind in range(len(cD)):\n",
    "        for i in range(3):\n",
    "            texture_features.append(self.get_stats_feature_vector(cD[detail_coeff_ind][1][i]))\n",
    "    return texture_features\n",
    "\n",
    "  def get_haar_features(self, tile, level = 4):\n",
    "    \"\"\"\n",
    "    Discrete wavelet transform (DWT) Haar wavelet based feature extraction\n",
    "\n",
    "    features:\n",
    "      1. stats used\n",
    "      2. input tile image\n",
    "      3. wavelet type\n",
    "      4. level of decomposition\n",
    "      5. coeff to use\n",
    "    return\n",
    "      1. feautre vector\n",
    "    \"\"\"\n",
    "    coeffs = pywt.wavedec2(tile, \"haar\", level=level)\n",
    "    cA, cD = coeffs[0], coeffs[1:]\n",
    "    texture_features = []\n",
    "\n",
    "    for detail_coeff in cD:\n",
    "        texture_features.append(self.get_stats_feature_vector(detail_coeff))\n",
    "\n",
    "    return texture_features\n",
    "\n",
    "  ########### Radon transform  ###############\n",
    "  def get_radon_features(self, tile):\n",
    "    \"\"\"\n",
    "    Radon transform based feature extraction\n",
    "\n",
    "    features:\n",
    "      1. stats used\n",
    "      2. input tile image\n",
    "      3. angle range in transform\n",
    "    input\n",
    "      1. tile - ndarray\n",
    "      2.\n",
    "    return\n",
    "      1. feautre vector\n",
    "    \"\"\"\n",
    "    theta = np.linspace(0., 180., max(tile.shape), endpoint=False)\n",
    "    sinogram = radon(tile, theta=theta, circle=False)\n",
    "    texture_features = self.get_stats_feature_vector(sinogram)\n",
    "    return texture_features\n",
    "\n",
    "\n",
    "  ############################################\n",
    "  ########## Clustering functions ############\n",
    "  ############################################\n",
    "\n",
    "  def fit_kmeans(self, feature_cube_flt, w, h):\n",
    "    \"\"\"\n",
    "    predict clusters from feature cube using k-means\n",
    "\n",
    "    features:\n",
    "      1. image dims\n",
    "      2. feature cube\n",
    "      3. no of clusters\n",
    "    return:\n",
    "      1. index map\n",
    "    \"\"\"\n",
    "    kmeans = KMeans(n_clusters=self.no_clusters)\n",
    "    kmeans.fit(dataset)\n",
    "    ind_out = kmeans.predict(dataset)\n",
    "    out_img = np.zeros((w*h), dtype = float)\n",
    "    for i in range(ind_out.shape[0]):\n",
    "        out_img[i]=ind_out[i]\n",
    "    index_map = out_img.reshape(w,h)\n",
    "    return index_map\n",
    "\n",
    "  def fit_gmm(self, feature_cube_flt, w, h):\n",
    "    \"\"\"\n",
    "    predict clusters from feature cube using gmm\n",
    "\n",
    "    features:\n",
    "      1. image dims\n",
    "      2. feature cube\n",
    "      3. no of clusters\n",
    "    return:\n",
    "      1. index map\n",
    "    \"\"\"\n",
    "    gmm = GaussianMixture(n_components=self.no_clusters)\n",
    "    gmm.fit(dataset)\n",
    "    ind_out = gmm.predict(dataset)\n",
    "    out_img = np.zeros((w*h), dtype = float)\n",
    "    for i in range(ind_out.shape[0]):\n",
    "        out_img[i]=ind_out[i]\n",
    "    index_map = out_img.reshape(w,h)\n",
    "    return index_map\n",
    "\n",
    "\n",
    "  ############################################\n",
    "  ############# Aux functions ################\n",
    "  ############################################\n",
    "\n",
    "  ########## stats for feature extraction and dimension reduction ##########\n",
    "  def get_stats_feature_vector(self, trans_out):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    trans_out = np.abs(trans_out)\n",
    "    trans_out = trans_out.flatten()\n",
    "    feature_vector = []\n",
    "\n",
    "    if \"a\" in self.stats_to_use:\n",
    "      mean_trans_out = np.mean(trans_out)\n",
    "      feature_vector.append(mean_trans_out)\n",
    "\n",
    "    if \"m\" in self.stats_to_use:\n",
    "      max_trans_out = np.max(trans_out)\n",
    "      feature_vector.append(max_trans_out)\n",
    "\n",
    "    if \"v\" in self.stats_to_use:\n",
    "      variance_trans_out = np.var(trans_out)\n",
    "      feature_vector.append(variance_trans_out)\n",
    "\n",
    "    if \"s\" in self.stats_to_use:\n",
    "      mean_trans_out = np.mean(trans_out)\n",
    "      variance_trans_out = np.var(trans_out)\n",
    "      skewness_trans_out = np.mean((trans_out - mean_trans_out) ** 3) / (variance_trans_out ** (3/2))\n",
    "      feature_vector.append(skewness_trans_out)\n",
    "\n",
    "    if \"k\" in self.stats_to_use:\n",
    "      mean_trans_out = np.mean(trans_out)\n",
    "      variance_trans_out = np.var(trans_out)\n",
    "      kurtosis_trans_out = np.mean((trans_out - mean_trans_out) ** 4) / (variance_trans_out ** 2)\n",
    "      feature_vector.append(kurtosis_trans_out)\n",
    "\n",
    "    return feature_vector\n",
    "\n",
    "  ########## PCA ##########\n",
    "  def processing_apply_pca(self, feature_cube_flt):\n",
    "    \"\"\"\n",
    "    function to apply pca on input\n",
    "\n",
    "    features:\n",
    "      1. no. of components\n",
    "    output:\n",
    "      1. PC1, PC2 ...\n",
    "    \"\"\"\n",
    "    feature_cube_flt = self.processing_normalization(feature_cube_flt)\n",
    "    pca = PCA(n_components=self.pca_comp)\n",
    "    principalComponents = pca.fit_transform(feature_cube_flt)\n",
    "    return principalComponents\n",
    "\n",
    "  ########## normalising ##########\n",
    "  def processing_normalization(self, feature_cube_flt):\n",
    "    \"\"\"\n",
    "    Discription: function to normalize values\n",
    "    features:\n",
    "      1. input data\n",
    "    return:\n",
    "      1. data stadardized\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    scaled_features = scaler.fit_transform(feature_cube_flt)\n",
    "    return scaled_features\n",
    "\n",
    "\n",
    "  def get_diameter_distribution(self, img):\n",
    "    \"\"\"\n",
    "03\n",
    "    um_pi -> length of one pix in nanometers\n",
    "    \"\"\"\n",
    "    thk = ps.filters.local_thickness(img)\n",
    "    plt.rcParams.update({'font.size': 14})\n",
    "    fig, ax = plt.subplots(1, 2, figsize=[10, 4], constrained_layout=True)\n",
    "\n",
    "    ax[0].tick_params(left = False, right = False , labelleft = False ,\n",
    "                    labelbottom = False, bottom = False)\n",
    "    #thk = thk*(2*um_pix)  # gives diameter therefore its 2 * scale of pix to nanometers\n",
    "    img0 = ax[0].imshow(thk*2*self.um_pix, cmap='viridis')\n",
    "\n",
    "    fig.colorbar(img0, ax=ax[0], orientation='vertical')\n",
    "    #thk = thk//(2*um_pix)\n",
    "    psd = ps.metrics.pore_size_distribution(im=thk*2*self.um_pix,log=False,bins=11)\n",
    "    #*2*um_pix  # gives diameter therefore its 2 * scale of pix to nanometers\n",
    "    ax[1].plot(psd.bin_centers[:-1], -1*np.diff(psd.cdf), color=\"black\")  # the results from the psd.pdf is very flaky. it gives different scales for different bin sizes and values check this out when free\n",
    "    ax[1].tick_params('x', top=True)\n",
    "    ax[1].tick_params('y', right=True)\n",
    "    ax[1].set_ylim([0, 0.3])\n",
    "    ax[1].yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "    return fig\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  segment = Segment(\n",
    "    pca_comp = 3,\n",
    "    pca_apply=False,\n",
    "    win_ratio = 0.03,\n",
    "    transform_string = \"dft_dlresnet50\", #\"dl_resnet50\",\n",
    "    stand_out_features = True,\n",
    "    eql_hist = False,\n",
    "    use_kmeans = True,\n",
    "    use_gmm = False,\n",
    "    no_clusters = 2,\n",
    "    stats_to_use = \"vas\",\n",
    "    um_pix=5.21,\n",
    "  )\n",
    "  inp_img = np.random.randint(low=0, high=254, size=(60,60), dtype=int)\n",
    "  feature_cube_flat, w, h = segment.slinding_window(inp_img)\n",
    "  feature_cube_flat = np.array(feature_cube_flat)\n",
    "  print(feature_cube_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "qUVqgUnuQdDc",
    "outputId": "2806616b-8bd5-4c00-c96d-25cec446f297"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-71f0fa579ad8>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mappend\u001b[0;34m(arr, values, axis)\u001b[0m\n\u001b[1;32m   5615\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5616\u001b[0m         \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5617\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)"
     ]
    }
   ],
   "source": [
    "a = np.random.randint(0,255,size=(16384, 768))\n",
    "b = np.array([])\n",
    "\n",
    "c = np.append(b, a, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4dEuzQ-exx1u"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
